---
layout: default
title: Research
---

<div class="page-header">
  <h1 class="page-title">Research</h1>
  <p class="page-subtitle">Bridging biological and artificial intelligence to understand how minds learn, reason, and discover.</p>
</div>

<div class="section">
  <div class="section-narrow">

    <div class="video-container">
      <video autoplay controls loop muted playsinline aria-describedby="video-desc">
        <source src="/sunlab/mesoscope.mp4" type="video/mp4">
        Your browser does not support the video tag.
      </video>
      <p class="video-caption">2-Photon calcium imaging of mouse hippocampus showing activities of over 5,000 neurons.</p>
    </div>

    <div class="video-description" id="video-desc">
      <strong>Video Description:</strong> This visualization shows real-time neural activity recorded from a mouse hippocampus using 2-photon calcium imaging. Each bright flash represents a neuron firing, with the imaging capturing over 5,000 neurons simultaneously. The hippocampus is a brain region critical for memory formation, spatial navigation, and learning—key areas of study in our lab.
    </div>

    <div class="research-text mt-12">
      <p>
        The Sun Lab investigates the computational principles underlying learning and cognition in biological systems, with the goal of using these insights to advance artificial intelligence. We operate at the intersection of systems neuroscience, computational modeling, and machine learning.
      </p>

      <p>
        On the neuroscience side, we employ modern techniques such as large-scale 2-photon calcium imaging to simultaneously record from thousands of neurons in behaving animals. This allows us to study how the brain—particularly the hippocampus—constructs <em>cognitive maps</em>: internal representations of the world that support flexible reasoning, planning, and generalization to novel situations.
      </p>

      <p>
        On the AI side, we leverage insights from how biological brains organize knowledge to develop neuro-inspired algorithms. Our work spans multiple frontiers of modern AI research, from improving how foundation models handle compositional generalization to building world models that enable more human-like reasoning and planning.
      </p>
    </div>

    <div class="focus-areas">
      <h2 class="focus-area-title">Current Research Directions</h2>

      <div class="focus-list stagger-children">
        <div class="focus-item">
          <svg class="focus-item-icon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true">
            <polyline points="22 12 18 12 15 21 9 3 6 12 2 12"></polyline>
          </svg>
          <span class="focus-item-text">Large-scale neural recordings of learning and memory formation</span>
        </div>

        <div class="focus-item">
          <svg class="focus-item-icon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true">
            <rect x="2" y="3" width="20" height="14" rx="2" ry="2"></rect>
            <line x1="8" y1="21" x2="16" y2="21"></line>
            <line x1="12" y1="17" x2="12" y2="21"></line>
          </svg>
          <span class="focus-item-text">Neuro-inspired compositional generalization in foundation models</span>
        </div>

        <div class="focus-item">
          <svg class="focus-item-icon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true">
            <circle cx="12" cy="12" r="10"></circle>
            <path d="M12 2a14.5 14.5 0 0 0 0 20 14.5 14.5 0 0 0 0-20"></path>
            <path d="M2 12h20"></path>
          </svg>
          <span class="focus-item-text">World models for reasoning and planning</span>
        </div>

        <div class="focus-item">
          <svg class="focus-item-icon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true">
            <path d="M2 3h6a4 4 0 0 1 4 4v14a3 3 0 0 0-3-3H2z"></path>
            <path d="M22 3h-6a4 4 0 0 0-4 4v14a3 3 0 0 1 3-3h7z"></path>
          </svg>
          <span class="focus-item-text">Complementary learning systems and memory consolidation</span>
        </div>

        <div class="focus-item">
          <svg class="focus-item-icon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true">
            <path d="M9.5 2A2.5 2.5 0 0 1 12 4.5v15a2.5 2.5 0 0 1-4.96.44 2.5 2.5 0 0 1-2.96-3.08 3 3 0 0 1-.34-5.58 2.5 2.5 0 0 1 1.32-4.24 2.5 2.5 0 0 1 4.44-1.04"></path>
            <path d="M14.5 2A2.5 2.5 0 0 0 12 4.5v15a2.5 2.5 0 0 0 4.96.44 2.5 2.5 0 0 0 2.96-3.08 3 3 0 0 0 .34-5.58 2.5 2.5 0 0 0-1.32-4.24 2.5 2.5 0 0 0-4.44-1.04"></path>
          </svg>
          <span class="focus-item-text">AI Scientists: autonomous agents for science automation</span>
        </div>
      </div>
    </div>

    <div class="research-text mt-12">
      <p>
        Additionally, the lab engages in software and hardware engineering to develop custom tools that support and streamline our research efforts. By combining cutting-edge neuroscience techniques, innovative AI algorithms, and purpose-built engineering solutions, we aim to advance our understanding of intelligence and push the boundaries of what is possible in both biological and artificial systems.
      </p>
    </div>

    <div class="featured-publication mt-12">
      <h2 class="focus-area-title">Featured Research</h2>
      <div class="featured-video-container">
        <div class="video-wrapper">
          <iframe
            src="https://www.youtube.com/embed/yw_4uVurFCo"
            title="Video Abstract: Learning produces an orthogonalized state machine in the hippocampus"
            frameborder="0"
            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
            allowfullscreen
            aria-describedby="featured-video-desc">
          </iframe>
        </div>
        <div class="featured-video-info">
          <h3 class="featured-video-title">Learning produces an orthogonalized state machine in the hippocampus</h3>
          <p class="featured-video-venue">Nature, 2025</p>
          <p class="featured-video-desc" id="featured-video-desc">This video abstract explains our discovery that the hippocampus organizes learned experiences into orthogonalized representations that function like a state machine, enabling flexible navigation through both physical and abstract spaces.</p>
          <a href="https://www.nature.com/articles/s41586-024-08548-w" target="_blank" rel="noopener noreferrer" class="btn btn-secondary">Read the Paper</a>
        </div>
      </div>
    </div>

  </div>
</div>
